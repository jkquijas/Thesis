% abstract.tex (Abstract)

\addcontentsline{toc}{chapter}{Abstract}

\chapter*{Abstract}
Convolutional neural networks have seen much success in computer vision natural language processing tasks.
Because of the large number of parameters in these model's, they are prone to overfitting
if not regularized appropriately or trained on a sufficiently large dataset.
In this work, we study the performance of convolutional neural models when the available training datasets
are of moderate size. We quantify the effects of model hyperparameters on classification performance
and propose several data augmentation techniques designed for text datasets.
Finally, we provide discussion on our empirical results.
