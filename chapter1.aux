\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Training a Neural Network}{1}}
\citation{bottou2010large}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Minimizing Non-Convex Functions: Gradiant-Based Learning}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Bias-Variance Tradeoff}{2}}
\citation{hinton2012improving}
\citation{hinton2012improving}
\citation{srivastava2014dropout}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Visualization of overfitting. Training error decreases as epochs progress, eventually reaching zero. Validation error starts increasing, indicating overfitting. The best model is shown at the dotted line, where validation error reached its minimum.}}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Weight Regularization}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Dropout}{5}}
\@setckpt{chapter1}{
\setcounter{page}{6}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{4}
\setcounter{subsection}{1}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{1}
\setcounter{table}{0}
\setcounter{definition}{0}
\setcounter{theorem}{0}
\setcounter{corollary}{0}
\setcounter{parentequation}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
}
